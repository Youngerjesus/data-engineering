# 데이터 팀의 역할 

## 데이터 조직의 목표 

- 다양한 데이터들을 데이터 웨어하우스에 적재하는 것. 
  - 데이터 웨어하우스는 데이터 분석을 위한 데이터베이스라고 알면 된다. 
  - 데이터 웨어하우스는 서비스 운영을 위한 데이터베이스가 아님. 
    - 유저 정보를 가지고 있고, 유저의 요구를 처리하는 데이터베이스
  - ETL: 데이터를 추출해서 데이터 웨어하우스에 적재하는 것
  - ELT: 데이터 웨어하우스에 적재된 데이터를 가지고 새로운 정보나 요약된 데이터들을 만들 떄 씀. 주로 데이터 분석에. 
    - DBT 라는 툴을 이용한다고함. 

- 목표: 신뢰할 수 있는 데이터를 가지고 부가가치를 만들어내는 것.
  - 기본적으로 데이터팀은 서포트 조직이다. 제조업 회사에 데이터 팀이 하는 일을 생각해봐라. 서포트만 할 것.
  - 부가가치는 다음과 같다.
    - 회사의 의사결정에 영향을 주는 것.
      - 의사결정은 data driven decision 과 data informed decision 이 있다. 
        - data driven 은 데이터가 시키는데로 결정하는 것
        - data informed 는 데이터를 참고만 하는 것. 
        - 미래의 일이 과거의 반복만 된다면 data-driven 이 맞지만 미래와 과거가 달라진다면 data informed 를 해야하는 것. 
        - 예를 들어서 코로나19 가 발생했다고 한다면 데이터 드리븐은 의미가 없을 수 있다. 완전히 달라진 것이기 때문에.
    - 고품질 데이터로 서비스의 기능을 개선하는 것
      - 머신러닝을 통해서 

### 커리어 

- ML Engineer 
  - Data Engineer + Data Scientist (ML 쪽)

- MLOps Engineer 
  - ML Engineer + DevOps. Machine Learning 모델을 계속해서 최신화하도록 만드는 것. 

***

# RedShift 소개 

### Redshift 란? 

- up to 2PB data in a cluster of servers 
- Still OLAP 
- Columnar Storage 
  - Column 기반으로 저장한다. 대규모 데이터를 처리할 때 속도가 더 나와서 
  - Per column compression is used 
- Support Bulk Update 
  - Upload CSV/JSON filed to S3 and copy from S3 to Redshift 
- Fixed Capacity SQL Engine 
  - vs Snowflake vs BigQuery 
- Doesn't guarantee primary key uniqueness
  - 이것도 속도 문제 때문에. 

### Redshift data type

- postrgesql 8 버전과 호환된다고 하길래 다 똑같은 줄 알았는데 그 중 일부분만 있다고 한다. 
- Postgresql 에서는 JSON 타입이 있는데 Redshift 에는 없음. 
- Char 같은 경우는 postrgresql 에서 2GB 까지 제한을 둘 수 있는데 Redshift 에서는 65KB 까지만 된다. 
- 완전히 똑같지는 않나보네. Redshift 가 좀 더 제한사항이 있다. 

### Storage Option 

- 여러가지 옵션이 있더라. Storage 에 집중하거나, Computing 에 집중하거나, 두 개를 다 가져가는 Managed Option 이 있다. 

### Redshift problem

- skew table 이 생길 수 있는 문제가 있다.
  - 한 노드에 데이터가 쏠리고, 다른 노드에는 데이터가 조금만 있는 균형이 안맞는 현상을 말한다.
  - 데이터가 한 노드에 많으니까 균등한 병렬 처리가 안되서 속도가 안나올 수 있다. 계속 데이터가 많은 노드에만 연산이 집중되니까. 
  - 데이터를 분산 저장할 때 Skew 현상이 있는지 알아보는 것도 중요하겠네.  

### Redshift 의 기능 확장 

![](./image/how%20to%20extend%20redshift%20functionality.png)

- LOG 파일 같은 경우는 비정형화 되어있음. 이걸 그대로 Redshift 에 적재하는 건 안됨. Redshift 의 테이블 구조는 정형화되어있어서.
그래서 AWS Athena 같은 걸 써서 정형화되게 만든다. 

### Bulk Update Sequence - COPY SQL 

![](./image/bulk%20update%20sequence.png)

- 하루에 데이터를 몇억건씩 넣구나. 그래서 보통 bulk insert, update 한다.
- Data source 에 있는 데이터들을 Airflow 에서 읽어서 file 로 만든다. 그걸 S3 에 올리고, S3 에 있는 데이터를 Redshift 에 한 큐로 올린다.
  - 이렇게 Bulk Update 하는 SQL 을 COPY 라고 한다. 

- COPY SQL 
  - 데이터를 빠르게 테이블간의 복사를 하거나, 내보낼 때, 가져올 때 쓴다.
  - 일반적으로 대량의 데이터를 빠르게 이동시키거나 가지고 올 때 쓴다. 


#### 테이블에서 파일로 내보내기 
```sql
COPY table_name TO 'file_path' [WITH options];
```

- 선택적으로 WITH 절을 사용하여 옵션을 지정할 수 있습니다. 일반적인 옵션에는 구분 기호(delimiter), 인용 구문(quote), 이스케이프 문자(escape), 헤더 유무(header), 인코딩(encoding) 등이 있습니다.

#### 테이블에서 파일로 내보내기. 쉼표로. 
```sql
COPY table_name TO '/path/to/your/file.csv' WITH (FORMAT CSV, HEADER);
```

#### 파일에서 테이블로 데이터 가져오기:

```sql
COPY table_name FROM 'file_path' [WITH options];
```
- 이 명령을 사용하여 외부 파일의 데이터를 테이블로 가져올 수 있습니다. 가져올 때도 선택적으로 WITH 절을 사용하여 옵션을 지정할 수 있습니다.
- 참고로, COPY 명령은 일부 데이터베이스 관리 시스템(DBMS)에서만 지원되며, 사용법과 옵션은 해당 시스템에 따라 다를 수 있습니다. 사용하려는 DBMS의 공식 문서를 참조하십시오.
  - 이 기능은 SNOW FLAKE, Google Cloud Big Query 에도 동일하게 있다. 

### Redshift Schema 

![](./image/redshift%20schema.png)

- raw_data: 데이터 엔지니어들이 ETL 을 통해서 데이터 웨어하우스에 적재한 schema
- analytics: 데이터 분석가들이 raw_data 를 통해서 ELT 한 후 적재하는 schema
- adhoc: raw_data 나 analytics 에 넣을 수는 없지만 테스트를 해봐야하는 등의 데이터들을 넣고 싶을 떄. 
- redshift 에서의 schema 가 mysql 에서는 database 라고 한다. 가장 밑단에는 테이블이 잇는 거고. 
  - 테이블도 테이블 구조를 테이블 schema 라고 부른다.

## 실습을 위한 배경지식 

### Raw Data Schema

- user 와 session 에 대한 테이블을 만들었음. 
  - session 은 user 가 광고채널에서 들어왔을 때 생기는 것으로 사용자의 방문을 나타낸다.
  - 이 정보를 바탕으로 다양한 데이터 분석이 가능하다. 

![](./image/session%20user%20table.png)
